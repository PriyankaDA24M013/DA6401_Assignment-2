{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11375238,"sourceType":"datasetVersion","datasetId":7121551}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"id\":\"zlXKfPwjwcA4\",\"outputId\":\"2a4b5e88-5a0f-45f8-a992-fb4716352f01\",\"jupyter\":{\"outputs_hidden\":false}}\n# from google.colab import drive\n# drive.mount('/content/drive')\n\n# %% [code] {\"id\":\"WpgM-v5_qrNw\",\"jupyter\":{\"outputs_hidden\":false}}\n# import zipfile\n# import os\n\n# zip_path = '/content/drive/MyDrive/DL_A2/nature_12K.zip'\n# extract_path = '/content/drive/MyDrive/DL_A2/dataset'  # or just '/content/' to extract here\n\n# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n#     zip_ref.extractall(extract_path)\n\n# %% [code] {\"id\":\"1mnZ4zYFw6GV\",\"outputId\":\"03d7da21-f49a-420f-af02-71bdf72de785\",\"execution\":{\"iopub.status.busy\":\"2025-04-24T07:50:18.150204Z\",\"iopub.execute_input\":\"2025-04-24T07:50:18.150405Z\",\"iopub.status.idle\":\"2025-04-24T07:50:18.600127Z\",\"shell.execute_reply.started\":\"2025-04-24T07:50:18.150387Z\",\"shell.execute_reply\":\"2025-04-24T07:50:18.599375Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nimport cv2\n\nimg = cv2.imread('/kaggle/input/dldata/inaturalist_12K/train/Amphibia/0012ec13b97dfbfb3dd5de8c3da95555.jpg')\nheight, width, channels = img.shape\nprint(f'Width: {width}, Height: {height}, Channels: {channels}')\n\n# %% [code] {\"id\":\"fKQT79IoxHFx\",\"outputId\":\"e6936f51-3ae7-4b37-c466-57f013523e52\",\"execution\":{\"iopub.status.busy\":\"2025-04-24T07:50:18.601552Z\",\"iopub.execute_input\":\"2025-04-24T07:50:18.601844Z\",\"iopub.status.idle\":\"2025-04-24T07:50:19.089705Z\",\"shell.execute_reply.started\":\"2025-04-24T07:50:18.601824Z\",\"shell.execute_reply\":\"2025-04-24T07:50:19.088965Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Load image using OpenCV\nimage_path = '/kaggle/input/dldata/inaturalist_12K/train/Amphibia/0012ec13b97dfbfb3dd5de8c3da95555.jpg'\nimage = cv2.imread(image_path)\n\n# Convert BGR (OpenCV default) to RGB for display\nimage_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# Display the image\nplt.figure(figsize=(10, 6))\nplt.imshow(image_rgb)\nplt.axis('off')\nplt.title(\"Sample Image\")\nplt.show()\n\n# %% [markdown] {\"id\":\"e4tZLavRxZ0Z\",\"jupyter\":{\"outputs_hidden\":false}}\n# # Part A\n\n# %% [markdown] {\"id\":\"dWGxxmtWxe7v\",\"jupyter\":{\"outputs_hidden\":false}}\n# ### Question 1\n# \n# \n# \n# Build a small CNN model consisting of 5 convolution layers. Each convolution layer would be followed by an activation and a max-pooling layer.\n# \n# After 5 such conv-activation-maxpool blocks, you should have one dense layer followed by the output layer containing 10 neurons (1 for each of the 10classes). The input layer should be compatible with the images in the iNaturalist dataset dataset.\n# \n# The code should be flexible such that the number of filters, size of filters, and activation function of the convolution layers and dense layers can be changed. You should also be able to change the number of neurons in the dense layer.\n\n# %% [code] {\"id\":\"z3oh5JLsxHIl\",\"execution\":{\"iopub.status.busy\":\"2025-04-24T04:53:45.165347Z\",\"iopub.execute_input\":\"2025-04-24T04:53:45.165955Z\",\"iopub.status.idle\":\"2025-04-24T04:53:49.046544Z\",\"shell.execute_reply.started\":\"2025-04-24T04:53:45.165932Z\",\"shell.execute_reply\":\"2025-04-24T04:53:49.045631Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n%pip install -q wandb\n\n# %% [code] {\"id\":\"eUu8HyCixHMf\",\"outputId\":\"5dee10b9-bf0f-4ea4-fc6c-0564907f8126\",\"execution\":{\"iopub.status.busy\":\"2025-04-24T07:50:26.811078Z\",\"iopub.execute_input\":\"2025-04-24T07:50:26.811859Z\",\"iopub.status.idle\":\"2025-04-24T07:50:35.585746Z\",\"shell.execute_reply.started\":\"2025-04-24T07:50:26.811828Z\",\"shell.execute_reply\":\"2025-04-24T07:50:35.585026Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nimport wandb\n\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\n\n# I have saved my API token with \"wandb_api\" as Label. \n# If you use some other Label make sure to change the same below. \nwandb_api = user_secrets.get_secret(\"WANDB_API_KEY\") \n\nwandb.login(key=wandb_api)\n\n# %% [code] {\"id\":\"x2alsNyDVbXO\",\"execution\":{\"iopub.status.busy\":\"2025-04-24T04:54:01.196904Z\",\"iopub.execute_input\":\"2025-04-24T04:54:01.197678Z\",\"iopub.status.idle\":\"2025-04-24T04:54:01.201227Z\",\"shell.execute_reply.started\":\"2025-04-24T04:54:01.197645Z\",\"shell.execute_reply\":\"2025-04-24T04:54:01.200477Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ndataset_path = \"/kaggle/input/dldata/inaturalist_12K/train\"\n\n# %% [code] {\"id\":\"NsA9ZCSa4UO2\",\"execution\":{\"iopub.status.busy\":\"2025-04-21T12:15:33.456659Z\",\"iopub.execute_input\":\"2025-04-21T12:15:33.456941Z\",\"iopub.status.idle\":\"2025-04-21T12:15:33.465417Z\",\"shell.execute_reply.started\":\"2025-04-21T12:15:33.456921Z\",\"shell.execute_reply\":\"2025-04-21T12:15:33.464814Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nimport os\nimport random\nimport wandb\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\n# For reproducibility\ndef set_seed(seed=42):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    random.seed(seed)\n\n# Define the CNN model\nclass CustomCNN(nn.Module):\n    def __init__(self, conv_params, dense_neurons, activation_fn, dropout=0.0, batch_norm=False):\n        super(CustomCNN, self).__init__()\n        layers = []\n        in_channels = 3\n        for out_channels, kernel_size in conv_params:\n            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=1))\n            if batch_norm:\n                layers.append(nn.BatchNorm2d(out_channels))\n            layers.append(activation_fn())\n            layers.append(nn.MaxPool2d(2))\n            in_channels = out_channels\n        self.conv = nn.Sequential(*layers)\n        self.flatten = nn.Flatten()\n        self.dense = nn.Sequential(\n            nn.Linear(out_channels * 7 * 7, dense_neurons),  # Assuming input size 224x224 â†’ downsampled 32x7x7\n            activation_fn(),\n            nn.Dropout(dropout),\n            nn.Linear(dense_neurons, 10)\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.flatten(x)\n        x = self.dense(x)\n        return x\n\n# Activation mapper\nactivation_map = {\n    \"relu\": nn.ReLU,\n    \"gelu\": nn.GELU,\n    \"silu\": nn.SiLU,\n    \"mish\": nn.Mish\n}\n\n# Stratified split\ndef stratified_split(dataset, test_size=0.2):\n    targets = [sample[1] for sample in dataset.samples]\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n    for train_idx, val_idx in sss.split(dataset.samples, targets):\n        train_dataset = Subset(dataset, train_idx)\n        val_dataset = Subset(dataset, val_idx)\n        return train_dataset, val_dataset\n\n# %% [code] {\"id\":\"l2Pug-lVmsAb\",\"execution\":{\"iopub.status.busy\":\"2025-04-14T13:59:51.677574Z\",\"iopub.execute_input\":\"2025-04-14T13:59:51.677947Z\",\"iopub.status.idle\":\"2025-04-14T13:59:51.690552Z\",\"shell.execute_reply.started\":\"2025-04-14T13:59:51.677930Z\",\"shell.execute_reply\":\"2025-04-14T13:59:51.689869Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ndef train_model(config=None, sweep=False):\n    # WandB init with thread-safe settings for Colab\n    if sweep:\n        run = wandb.init(config=config, settings=wandb.Settings(start_method=\"thread\"))\n        config = wandb.config\n    else:\n        if config is not None:\n            config.update(config)\n        run = wandb.init(\n            project=\"DA6401-A2\",\n            config=config,\n            name=None,\n            reinit=True,\n            settings=wandb.Settings(start_method=\"thread\")\n        )\n        config = wandb.config  # Ensure consistency\n\n    # Run name for better visualization\n    run_name = (\n        f\"nl_{config['num_filters']}_bs_{config['batch_size']}_\"\n        f\"hs_{config['dense_neurons']}_ac_{config['activation']}_\"\n        f\"dr_{config['dropout']}_bn_{int(config['batch_norm'])}\"\n    )\n    wandb.run.name = run_name\n    wandb.run.save()\n\n    set_seed()\n\n    # Data transforms\n    base_transforms = [transforms.Resize((224, 224)), transforms.ToTensor()]\n    if config[\"data_aug\"]:\n        base_transforms.insert(0, transforms.RandomHorizontalFlip())\n        base_transforms.insert(0, transforms.RandomRotation(15))\n    transform = transforms.Compose(base_transforms)\n\n    dataset = datasets.ImageFolder(dataset_path, transform=transform)\n    train_dataset, val_dataset = stratified_split(dataset)\n\n    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=2)\n    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=2)\n\n    # Conv architecture config\n    if config[\"filter_scheme\"] == \"same\":\n        conv_params = [(config[\"num_filters\"], 3)] * 5\n    elif config[\"filter_scheme\"] == \"double\":\n        conv_params = [(config[\"num_filters\"] * (2**i), 3) for i in range(5)]\n    else:  # halving\n        conv_params = [(max(8, config[\"num_filters\"] // (2**i)), 3) for i in range(5)]\n\n    model = CustomCNN(\n        conv_params,\n        config[\"dense_neurons\"],\n        activation_map[config[\"activation\"]],\n        config[\"dropout\"],\n        config[\"batch_norm\"]\n    )\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n\n    best_val_acc = 0\n    best_epoch = -1\n\n    for epoch in range(config[\"epochs\"]):\n        model.train()\n        running_loss, correct, total = 0.0, 0, 0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n        train_acc = 100. * correct / total\n        val_acc = evaluate(model, val_loader, device)\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_epoch = epoch + 1\n            if not sweep:\n                torch.save(model.state_dict(), \"best_model.pth\")\n                wandb.save(\"best_model.pth\")\n\n        wandb.log({\n            \"epoch\": epoch + 1,\n            \"loss\": running_loss / len(train_loader),\n            \"train_acc\": train_acc,\n            \"val_acc\": val_acc\n        })\n\n        print(f\"Epoch {epoch+1}/{config['epochs']}: \"\n              f\"Loss: {running_loss / len(train_loader):.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n\n    # Final results\n    if not sweep:\n        print(\"\\nTraining Completed!\")\n        print(f\"Best Val Acc: {best_val_acc:.2f}% at epoch {best_epoch}\")\n        print(\"Best Parameters:\")\n        for k, v in config.items():\n            print(f\"  {k}: {v}\")\n\n    wandb.run.summary[\"best_val_acc\"] = best_val_acc\n    wandb.run.summary[\"best_epoch\"] = best_epoch\n    wandb.finish()\n\n# %% [code] {\"id\":\"gApl1Puxmy6C\",\"execution\":{\"iopub.status.busy\":\"2025-04-14T13:59:55.446997Z\",\"iopub.execute_input\":\"2025-04-14T13:59:55.447652Z\",\"iopub.status.idle\":\"2025-04-14T13:59:55.452045Z\",\"shell.execute_reply.started\":\"2025-04-14T13:59:55.447630Z\",\"shell.execute_reply\":\"2025-04-14T13:59:55.451237Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n\n# Evaluation function\ndef evaluate(model, loader, device):\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n    return 100. * correct / total\n\n# %% [code] {\"id\":\"NGi96QHiTK2V\",\"outputId\":\"511e2441-b25b-4895-ad11-e75e5f558477\",\"execution\":{\"iopub.status.busy\":\"2025-04-12T17:27:46.735395Z\",\"iopub.execute_input\":\"2025-04-12T17:27:46.735949Z\",\"iopub.status.idle\":\"2025-04-12T17:27:46.752731Z\",\"shell.execute_reply.started\":\"2025-04-12T17:27:46.735928Z\",\"shell.execute_reply\":\"2025-04-12T17:27:46.752095Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# sweep_config = {\n#     \"method\": \"bayes\",\n#     \"metric\": {\"name\": \"val_acc\", \"goal\": \"maximize\"},\n#     \"parameters\": {\n#         \"epochs\": {\"value\": 5},\n#         \"lr\": {\"values\": [1e-3, 5e-4, 1e-4]},\n#         \"batch_size\": {\"values\": [32, 64]},\n#         \"num_filters\": {\"values\": [32, 64]},\n#         \"filter_scheme\": {\"values\": [\"same\", \"double\", \"half\"]},\n#         \"activation\": {\"values\": [\"relu\", \"gelu\", \"silu\", \"mish\"]},\n#         \"dropout\": {\"values\": [0.2, 0.3]},\n#         \"dense_neurons\": {\"values\": [128, 256]},\n#         \"data_aug\": {\"values\": [True, False]},\n#         \"batch_norm\": {\"values\": [True, False]},\n#     }\n# }\n\n# sweep_id = wandb.sweep(sweep_config, project=\"DA6401-A2\")\n# wandb.agent(sweep_id, function=train_model, count=100)  # Run 10 trials\n\n# %% [code] {\"id\":\"b57fN1cQTK5n\",\"outputId\":\"102ab61c-a71a-4e2e-c254-6ccc09f547d1\",\"execution\":{\"iopub.status.busy\":\"2025-04-14T14:00:13.774346Z\",\"iopub.execute_input\":\"2025-04-14T14:00:13.774648Z\",\"iopub.status.idle\":\"2025-04-14T14:31:14.287135Z\",\"shell.execute_reply.started\":\"2025-04-14T14:00:13.774627Z\",\"shell.execute_reply\":\"2025-04-14T14:31:14.286359Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nbest_config = {\n    \"epochs\": 25,\n    \"lr\": 0.0001,\n    \"batch_size\": 32,\n    \"num_filters\": 64,\n    \"filter_scheme\": \"same\",\n    \"activation\": \"silu\",\n    \"dropout\": 0.3,\n    \"dense_neurons\": 256,\n    \"data_aug\": True,\n    \"batch_norm\": True\n}\n\n\ntrain_model(best_config, sweep=False)\n\n# %% [code] {\"id\":\"bavWC5y6hz-I\",\"execution\":{\"iopub.status.busy\":\"2025-04-14T15:02:14.913808Z\",\"iopub.execute_input\":\"2025-04-14T15:02:14.914562Z\",\"iopub.status.idle\":\"2025-04-14T15:02:53.401143Z\",\"shell.execute_reply.started\":\"2025-04-14T15:02:14.914534Z\",\"shell.execute_reply\":\"2025-04-14T15:02:53.400314Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torchvision.utils import make_grid\n\n# === 1. Define test transforms (no augmentation) ===\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])\n\n# === 2. Load the test dataset ===\ntest_path = \"/kaggle/input/dldata/inaturalist_12K/val\"\ntest_dataset = datasets.ImageFolder(test_path, transform=test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\nclass_names = test_dataset.classes\n\n# === 3. Load your best model ===\n# Rebuild the model with best config\nbest_config = {\n    \"epochs\": 25,\n    \"lr\": 0.0001,\n    \"batch_size\": 32,\n    \"num_filters\": 64,\n    \"filter_scheme\": \"same\",\n    \"activation\": \"silu\",\n    \"dropout\": 0.3,\n    \"dense_neurons\": 256,\n    \"data_aug\": True,\n    \"batch_norm\": True\n}\n\nif best_config[\"filter_scheme\"] == \"same\":\n    conv_params = [(best_config[\"num_filters\"], 3)] * 5\nelif best_config[\"filter_scheme\"] == \"double\":\n    conv_params = [(best_config[\"num_filters\"] * (2**i), 3) for i in range(5)]\nelse:\n    conv_params = [(max(8, best_config[\"num_filters\"] // (2**i)), 3) for i in range(5)]\n\nmodel = CustomCNN(\n    conv_params,\n    best_config[\"dense_neurons\"],\n    activation_map[best_config[\"activation\"]],\n    best_config[\"dropout\"],\n    best_config[\"batch_norm\"]\n)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Load the weights\nmodel.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\nmodel.eval()\n\n# === 4. Evaluate on test set ===\ncorrect, total = 0, 0\nall_preds, all_labels = [], []\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n        all_preds.extend(predicted.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\ntest_acc = 100. * correct / total\nprint(f\"Test Accuracy: {test_acc:.2f}%\")\n\n# === 5. Log to W&B ===\nwandb.init(project=\"DA6401-A2\", name=\"best_model_test_eval\")\nwandb.log({\"test_accuracy\": test_acc})\n\n# === 6. Create and log 10Ã—3 prediction grid ===\nfig, axs = plt.subplots(10, 3, figsize=(12, 40))\nindices = np.random.choice(len(test_dataset), 30, replace=False)\n\nfor ax, idx in zip(axs.flatten(), indices):\n    image, label = test_dataset[idx]\n    input_tensor = image.unsqueeze(0).to(device)\n    output = model(input_tensor)\n    pred = output.argmax(1).item()\n\n    ax.imshow(image.permute(1, 2, 0).cpu())\n    ax.set_title(f\"True: {class_names[label]}\\nPred: {class_names[pred]}\")\n    ax.axis('off')\n\nplt.tight_layout()\nwandb.log({\"Test Predictions Grid\": wandb.Image(fig)})\nwandb.finish()\n\n# %% [markdown] {\"jupyter\":{\"outputs_hidden\":false}}\n# # Part B\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-24T07:50:58.354471Z\",\"iopub.execute_input\":\"2025-04-24T07:50:58.355225Z\",\"iopub.status.idle\":\"2025-04-24T08:12:49.376819Z\",\"shell.execute_reply.started\":\"2025-04-24T07:50:58.355193Z\",\"shell.execute_reply\":\"2025-04-24T08:12:49.376039Z\"}}\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport random\nimport wandb\nimport matplotlib.pyplot as plt\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\nrandom.seed(42)\n\n# Start wandb\nwandb.init(project=\"DA6401-A2\", name=\"resnet50_default_transfer\")\n\n# Basic Config\nepochs = 20\nlr = 0.0001\nbatch_size = 32\nimg_size = 224\ntrain_path = \"/kaggle/input/dldata/inaturalist_12K/train\"\n\n# Data Transforms (No augmentation â€” just Resize, ToTensor, Normalize)\ntransform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\n# Dataset and Stratified Split\ndataset = datasets.ImageFolder(train_path, transform=transform)\ntargets = [s[1] for s in dataset.samples]\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\ntrain_idx, val_idx = next(sss.split(dataset.samples, targets))\n\ntrain_dataset = Subset(dataset, train_idx)\nval_dataset = Subset(dataset, val_idx)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n\n# Load Pretrained ResNet50\nmodel = models.resnet50(pretrained=True)\n\n# Freeze all layers\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replace final fully connected layer\nnum_classes = len(dataset.classes)\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)\n\n# Move to device\nmodel = model.to(device)\n\n# Loss and Optimizer (only for fc layer)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=lr)\n\n# Accuracy Calculation Function\ndef evaluate(model, loader):\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            outputs = model(x)\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == y).sum().item()\n            total += y.size(0)\n    return 100. * correct / total\n\n# Training Loop\ntrain_accs, val_accs = [], []\n\nfor epoch in range(epochs):\n    model.train()\n    correct, total = 0, 0\n    running_loss = 0\n\n    for x, y in train_loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        outputs = model(x)\n        loss = criterion(outputs, y)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, preds = outputs.max(1)\n        total += y.size(0)\n        correct += (preds == y).sum().item()\n\n    train_acc = 100. * correct / total\n    val_acc = evaluate(model, val_loader)\n\n    train_accs.append(train_acc)\n    val_accs.append(val_acc)\n\n    wandb.log({\n        \"epoch\": epoch + 1,\n        \"train_loss\": running_loss / len(train_loader),\n        \"train_acc\": train_acc,\n        \"val_acc\": val_acc\n    })\n\n    print(f\"Epoch {epoch+1}: Train Acc = {train_acc:.2f}%, Val Acc = {val_acc:.2f}%\")\n\n# Save Model\ntorch.save(model.state_dict(), \"resnet50_default_finetuned.pth\")\nwandb.save(\"resnet50_default_finetuned.pth\")\n\n# Accuracy Plot\nplt.plot(train_accs, label=\"Train Acc\")\nplt.plot(val_accs, label=\"Val Acc\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy (%)\")\nplt.title(\"Train vs Val Accuracy (Default ResNet50)\")\nplt.legend()\nplt.grid(True)\nplt.savefig(\"accuracy_plot.png\")\nwandb.log({\"accuracy_plot\": wandb.Image(\"accuracy_plot.png\")})\n\nwandb.finish()\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-24T08:12:49.378150Z\",\"iopub.execute_input\":\"2025-04-24T08:12:49.378498Z\",\"iopub.status.idle\":\"2025-04-24T08:13:20.274156Z\",\"shell.execute_reply.started\":\"2025-04-24T08:12:49.378478Z\",\"shell.execute_reply\":\"2025-04-24T08:13:20.272994Z\"}}\nimport torch\nimport torch.nn as nn\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport wandb\nimport os\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Start wandb\nwandb.init(project=\"DA6401-A2\", name=\"resnet50_default_test\")\n\n# Config\nimg_size = 224\nbatch_size = 32\nval_path = \"/kaggle/input/dldata/inaturalist_12K/val\"\nmodel_path = \"resnet50_default_finetuned.pth\"\n\n# Data transforms (same as training)\ntransform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\n# Load Dataset\nval_dataset = datasets.ImageFolder(val_path, transform=transform)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\nclass_names = val_dataset.classes\n\n# Load Pretrained Model\nmodel = models.resnet50(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replace final layer\nnum_classes = len(class_names)\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)\nmodel.load_state_dict(torch.load(model_path, map_location=device))\nmodel = model.to(device)\nmodel.eval()\n\n# Accuracy Calculation\ncorrect, total = 0, 0\npredictions, actuals, images = [], [], []\n\nwith torch.no_grad():\n    for x, y in val_loader:\n        x, y = x.to(device), y.to(device)\n        outputs = model(x)\n        _, preds = torch.max(outputs, 1)\n        correct += (preds == y).sum().item()\n        total += y.size(0)\n\n        predictions.extend(preds.cpu().numpy())\n        actuals.extend(y.cpu().numpy())\n        images.extend(x.cpu())\n\ntest_acc = 100. * correct / total\nprint(f\"Test Accuracy: {test_acc:.2f}%\")\nwandb.log({\"Test Accuracy\": test_acc})\n\n# Visualizing Predictions\ndef imshow(img):\n    img = img.permute(1, 2, 0).numpy()\n    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # Unnormalize\n    img = np.clip(img, 0, 1)\n    return img\n\n# Show 16 images with predictions\nplt.figure(figsize=(12, 12))\nfor i in range(16):\n    plt.subplot(4, 4, i+1)\n    img = imshow(images[i])\n    plt.imshow(img)\n    plt.title(f\"P: {class_names[predictions[i]]}\\nA: {class_names[actuals[i]]}\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.savefig(\"predictions_grid.png\")\nwandb.log({\"Prediction Grid\": wandb.Image(\"predictions_grid.png\")})\n\nwandb.finish()\n","metadata":{"_uuid":"6dd5718f-5f03-4c81-b53e-c97560b74b53","_cell_guid":"04810915-b0ff-46ec-a782-4db3f32d08e6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}